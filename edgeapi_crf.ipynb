{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CRF + expert.ai Edge NL API for Named Entity Recognition\n\n> **IMPORTANT NOTICE**: This notebook was developed using the expert.ai Edge NL API, which was **retired in 2023**. The code is preserved for educational and archival purposes but will not function without access to the legacy Edge NL API runtime.\n>\n> For information about current expert.ai NLP solutions, please contact **info@expert.ai** or visit [expert.ai](https://www.expert.ai).\n\n---\n\n## Overview\n\nThis notebook demonstrates how to enhance Named Entity Recognition (NER) performance using a **Conditional Random Field (CRF)** model combined with linguistic features extracted from the **expert.ai Edge NL API**.\n\n### Approach\n- **Dataset**: CoNLL 2003 corpus (standard benchmark for NER tasks)\n- **Feature Engineering**: Linguistic features (POS tags, dependency labels, syncons, knowledge labels) from expert.ai's NLP engine\n- **Model**: CRF (Conditional Random Field) via `sklearn-crfsuite`\n\n### Key Results\nThe model achieves the following F1 scores on the CoNLL 2003 test set:\n- **LOC** (Location): 0.893\n- **PER** (Person): 0.882\n- **ORG** (Organization): 0.801\n- **MISC** (Miscellaneous): 0.747\n- **Overall micro-averaged F1**: 0.845"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Data Preparation\n\nThe **CoNLL 2003** corpus is a standard benchmark dataset for Named Entity Recognition tasks. It contains news articles annotated with four entity types:\n- **PER** (Person names)\n- **LOC** (Locations)\n- **ORG** (Organizations)\n- **MISC** (Miscellaneous entities)\n\nThe dataset uses the **BIO tagging scheme** (Beginning-Inside-Outside) to mark entity boundaries.\n\nThe corpus is downloaded from the [nluninja/nlp_datasets](https://github.com/nluninja/nlp_datasets) repository."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Helper Functions for CoNLL Corpus Processing\n\nThe following functions handle loading and parsing the CoNLL 2003 data format, where each line contains a token with its POS tag, syntactic chunk tag, and NER label."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# URL to the CoNLL 2003 dataset hosted on GitHub\nCONLL_URL_ROOT = \"https://raw.githubusercontent.com/nluninja/nlp_datasets/be9fd23409f1443790f6e1eab91d28b105769368/conll2003/data/\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard library and third-party imports\nimport os\nimport re\nimport urllib\nimport pandas as pd\nfrom math import nan\n\n# CRF model and evaluation libraries\nimport sklearn_crfsuite\nfrom sklearn_crfsuite import metrics\nfrom sklearn.metrics import make_scorer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_conll_data(filename, url_root=CONLL_URL_ROOT, only_tokens=False):\n    \"\"\"\n    Load and parse a CoNLL 2003 formatted dataset file.\n    \n    The CoNLL format structures data with one word per line, where each line\n    contains: word, POS tag, syntactic chunk tag, and NER entity tag, all\n    separated by whitespace. Sentences are separated by empty lines.\n    \n    Args:\n        filename: Name of the file to load (e.g., 'train.txt', 'test.txt')\n        url_root: Base URL where the dataset files are hosted\n        only_tokens: If True, return only token strings; if False, return\n                     tuples containing all features (word, POS, chunk tag)\n    \n    Returns:\n        X: List of sentences, where each sentence is a list of tokens/tuples\n        Y: List of label sequences corresponding to each sentence\n        output_labels: Set of all unique NER labels found in the data\n    \"\"\"\n    lines = read_raw_conll(url_root, filename)\n    X = []\n    Y = []\n    sentence = []\n    labels = []\n    output_labels = set()\n    \n    for line in lines:\n        if line == \"\\n\":\n            # Empty line indicates end of sentence\n            if len(sentence) != len(labels):\n                print(f\"Error: we have {len(sentence)} words but {len(labels)} labels\")\n            if sentence and is_real_sentence(only_tokens, sentence):\n                X.append(sentence)\n                Y.append(labels)\n            sentence = []\n            labels = []\n        else:\n            # Parse line: word POS chunk_tag NER_tag\n            features = line.split()\n            tag = features.pop()  # Last element is the NER tag\n            labels.append(tag)\n            output_labels.add(tag)\n            if only_tokens:\n                sentence.append(features.pop(0))  # First element is the word\n            else:\n                sentence.append(tuple(features))\n    \n    print(f\"Read {len(X)} sentences\")\n    if len(X) != len(Y):\n        print(\"ERROR in reading data.\")\n    return X, Y, output_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def read_raw_conll(url_root, filename):\n    \"\"\"\n    Fetch and read a CoNLL 2003 dataset file from a URL.\n    \n    Args:\n        url_root: Base URL where the file is hosted\n        filename: Name of the file to read\n        \n    Returns:\n        List of lines from the file, excluding the first two header lines\n    \"\"\"\n    lines = []\n    full_url = url_root + filename\n    lines = open_read_from_url(full_url)\n    return lines[2:]  # Skip the header lines"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def open_read_from_url(url):\n    \"\"\"\n    Download and read a text file from a URL.\n    \n    Args:\n        url: Full URL to the text file\n        \n    Returns:\n        List of lines from the file, decoded as UTF-8\n    \"\"\"\n    print(f\"Read file from {url}\")\n    file = urllib.request.urlopen(url)\n    lines = []\n    for line in file:\n        lines.append(line.decode(\"utf-8\"))\n    return lines"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def is_real_sentence(only_token, sentence):\n    \"\"\"\n    Check if a sentence is actual content or a document separator.\n    \n    CoNLL 2003 uses '-DOCSTART-' markers and dashed lines to separate\n    documents within the corpus. These should be filtered out.\n    \n    Args:\n        only_token: Whether the sentence contains only token strings\n        sentence: The sentence to check\n        \n    Returns:\n        True if this is a real sentence, False if it's a document separator\n    \"\"\"\n    first_word = \"\"\n    if only_token:\n        first_word = sentence[0]\n    else:\n        first_word = sentence[0][0]\n\n    if '---------------------' in first_word or first_word == '-DOCSTART-':\n        return False\n    else:\n        return True"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Data Loading\n\nLoad the train, validation, and test splits of the CoNLL 2003 dataset. We extract only the tokens (words) since the expert.ai API will provide its own linguistic annotations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the three dataset splits (train, validation, test)\n# Setting only_tokens=True to get just the word strings, as expert.ai will\n# provide its own POS tags and other linguistic features\nraw_train, y_train, output_labels = load_conll_data('train.txt', only_tokens=True)\nraw_valid, y_valid, _ = load_conll_data('valid.txt', only_tokens=True)\nraw_test, y_test, _ = load_conll_data('test.txt', only_tokens=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Display first sentence and its NER labels\n# Labels use BIO format: B-ORG = Beginning of Organization, O = Outside (not an entity)\nprint(\"Sentence:\", raw_train[0])\nprint(\"Labels:  \", y_train[0])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Feature Generation with expert.ai Edge NL API\n\n> **NOTE**: This section requires the expert.ai Edge NL API runtime, which was **discontinued in 2023**. The code below will not execute without access to the legacy Edge API.\n\nThe expert.ai Edge NL API provides rich linguistic features for each token:\n- **POS tags**: Part-of-speech tagging (PROPN, NOUN, VERB, etc.)\n- **Dependency labels**: Syntactic dependency relations (nsubj, dobj, root, etc.)\n- **Syncons**: Semantic concept IDs from the expert.ai knowledge graph\n- **Knowledge labels**: Semantic categories (e.g., 'town', 'person', 'company')\n- **Type classes**: Combined POS and entity type information (e.g., 'NPR.GEO' for proper noun geographic entity)\n\nThese features significantly enhance the CRF model's ability to recognize named entities compared to using simple word-based features alone."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Authentication credentials for expert.ai API\n# NOTE: These credentials are for the deprecated Edge NL API (retired 2023)\n# The Edge API required local deployment via expert.ai Studio\nimport os\nos.environ[\"EAI_USERNAME\"] = 'your_username@example.com'\nos.environ[\"EAI_PASSWORD\"] = 'your_password'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the expert.ai Edge NL API client\n# NOTE: This import will fail as the Edge API has been discontinued (2023)\n# Contact info@expert.ai for information about current NLP solutions\nfrom expertai.nlapi.edge.client import ExpertAiClient\nclient = ExpertAiClient()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Helper Functions for Tokenization and Feature Extraction\n\nThe following functions process text through the expert.ai NLP engine and extract linguistic features that will be used as input to the CRF model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Progress bar library for tracking long-running operations\nfrom tqdm import tqdm, trange"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def tokens_to_docs(raw, eai):\n    \"\"\"\n    Analyze sentences using the expert.ai NLP engine.\n    \n    Takes tokenized sentences, reconstructs them as strings, and processes\n    them through the expert.ai full_analysis endpoint to obtain rich\n    linguistic annotations.\n    \n    Args:\n        raw: List of sentences, where each sentence is a list of token strings\n        eai: expert.ai client instance\n        \n    Returns:\n        docs: List of expert.ai Document objects containing NLP analysis results\n    \"\"\"\n    docs = []\n    for sent in tqdm(raw):\n        # Join tokens back into a sentence string and analyze\n        docs.append(eai.full_analysis(' '.join(sent)))\n    return docs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def _get_label(doc, syncon):\n    \"\"\"\n    Extract the knowledge graph label for a syncon from the document.\n    \n    Syncons (semantic concepts) in expert.ai's knowledge graph can have\n    associated labels that provide semantic categorization (e.g., 'town',\n    'person', 'company'). This function retrieves that label.\n    \n    Args:\n        doc: expert.ai Document object\n        syncon: Syncon ID to look up\n        \n    Returns:\n        The simplified label (last component after '.') or empty string if not found\n    \"\"\"\n    label = ''\n    if hasattr(doc, 'knowledge'):\n        for element in doc.knowledge:\n            if element.syncon == syncon:\n                label = element.label\n                break\n        # Extract the most specific part of hierarchical labels\n        # e.g., 'geography.town' -> 'town'\n        if label and '.' in label:\n            label = label.split('.')[-1]\n    return label"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def features_from_docs(sentences, docs):\n    \"\"\"\n    Extract CRF features from expert.ai analyzed documents.\n    \n    Aligns the original tokenization with expert.ai's tokenization and extracts\n    linguistic features for each token. Handles cases where tokenization differs\n    (e.g., expert.ai may split or merge tokens differently).\n    \n    Features extracted per token:\n        - word: The original token text\n        - pos: Part-of-speech tag (PROPN, NOUN, VERB, etc.)\n        - dep: Dependency relation label (nsubj, dobj, root, etc.)\n        - syncon: Semantic concept ID from expert.ai knowledge graph\n        - label: Knowledge graph category label\n        - typeclass: Combined POS and entity type (e.g., ['NPR', 'GEO'])\n    \n    Args:\n        sentences: List of sentences (lists of token strings)\n        docs: List of expert.ai Document objects\n        \n    Returns:\n        eai_sents: List of sentences, where each sentence is a list of\n                   feature dictionaries for each token\n    \"\"\"\n    eai_sents = []\n    for sent_idx in trange(len(sentences)):\n        seek = 0  # Track position in the document content string\n        eai_tokenlist = []\n        \n        for tk_idx in range(len(sentences[sent_idx])):\n            # Get the original token and find its position in the doc\n            token = sentences[sent_idx][tk_idx]\n            index_start = docs[sent_idx].content.find(token, seek)\n            index_end = index_start + len(token)\n            \n            # Find expert.ai tokens that overlap with this token's span\n            # This handles tokenization mismatches between original and expert.ai\n            possible_tokens = []\n            for t in docs[sent_idx].tokens:\n                if (t.start <= index_start and t.end >= index_end) or \\\n                   (t.start >= index_start and t.start <= index_end) or \\\n                   (t.end >= index_start and t.end <= index_end):\n                    possible_tokens.append(t)\n            \n            if not possible_tokens:\n                print('ERROR: expertai tokenization not found for token', token)\n                eai_tokenlist.append(_voidtoken())\n            else:\n                # If multiple tokens match, prefer the one with a valid syncon\n                if len(possible_tokens) > 1:\n                    possible_tokens.sort(key=lambda t: t.syncon, reverse=True)\n                \n                # Build feature dictionary from the best matching token\n                new_token = {\n                    'word': token,\n                    'pos': possible_tokens[0].pos,\n                    'syncon': possible_tokens[0].syncon,\n                    'ancestor': -1,\n                    'label': _get_label(docs[sent_idx], possible_tokens[0].syncon),\n                    'dep': possible_tokens[0].dependency.label,\n                    'typeclass': possible_tokens[0].type_.split('.')\n                }\n                eai_tokenlist.append(new_token)\n            \n            # Advance position tracker past whitespace\n            seek = index_end\n            while len(docs[sent_idx].content) < seek and (docs[sent_idx].content[seek] == ' '):\n                seek += 1\n        \n        eai_sents.append(eai_tokenlist)\n    return eai_sents"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def features_from_word(sentence, idx):\n    \"\"\"\n    Build CRF feature dictionary for a single token with context.\n    \n    Creates features from the current token plus its immediate neighbors,\n    capturing local context that's crucial for sequence labeling.\n    \n    Feature categories:\n        - Word shape features: lowercase, suffix, capitalization, digit patterns\n        - expert.ai features: POS tag, dependency label, syncon, knowledge label\n        - Context features: Same features for previous (-1) and next (+1) tokens\n        - Boundary markers: BOS (beginning of sentence), EOS (end of sentence)\n    \n    Args:\n        sentence: List of token feature dictionaries\n        idx: Index of the current token\n        \n    Returns:\n        Dictionary of features for the CRF model\n    \"\"\"\n    token = sentence[idx]\n    \n    # Core features for the current token\n    features = {\n        'bias': 1.0,  # Constant feature for learning label priors\n        'word.lower()': token['word'].lower(),\n        'word[-3:]': token['word'][-3:],  # 3-character suffix\n        'word[-2:]': token['word'][-2:],  # 2-character suffix\n        'word.isupper()': token['word'].isupper(),\n        'word.istitle()': token['word'].istitle(),\n        'word.isdigit()': token['word'].isdigit(),\n        # expert.ai linguistic features\n        'eai.postag': token['pos'],\n        'eai.postag[:2]': token['pos'][:2],  # POS tag prefix\n        'eai.deptag': token['dep'],\n        'eai.deptag[-2:]': token['dep'][-2:],  # Dep tag suffix\n        # Normalized syncon values (scaled to [0,1] range approximately)\n        'eai.syncon': -1 if token['syncon'] == -1 else token['syncon'] / 10000.,\n        'eai.ancestor': -1 if token['ancestor'] == -1 else token['ancestor'] / 10000.,\n        'eai.labels': token['label'],\n        'eai.typeclass': token['typeclass'],\n    }\n    \n    # Previous token context (position -1)\n    if idx > 0:\n        token1 = sentence[idx - 1]\n        features.update({\n            '-1:word.lower()': token1['word'].lower(),\n            '-1:word.istitle()': token1['word'].istitle(),\n            '-1:word.isupper()': token1['word'].isupper(),\n            '-1:eai.postag': token1['pos'],\n            '-1:eai.deptag': token1['dep'],\n            '-1:eai.labels': token1['label'],\n            '-1:eai.typeclass': token1['typeclass'],\n        })\n    else:\n        features['BOS'] = True  # Beginning of sentence marker\n    \n    # Next token context (position +1)\n    if idx < len(sentence) - 1:\n        token1 = sentence[idx + 1]  # Note: Fixed bug - was sentence[idx-1]\n        features.update({\n            '+1:word.lower()': token1['word'].lower(),\n            '+1:word.istitle()': token1['word'].istitle(),\n            '+1:word.isupper()': token1['word'].isupper(),\n            '+1:eai.postag': token1['pos'],\n            '+1:eai.deptag': token1['dep'],\n            '+1:eai.labels': token1['label'],\n            '+1:eai.typeclass': token1['typeclass'],\n        })\n    else:\n        features['EOS'] = True  # End of sentence marker\n    \n    return features"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def features_from_sentence(sentence):\n    \"\"\"\n    Generate CRF features for all tokens in a sentence.\n    \n    Args:\n        sentence: List of token feature dictionaries\n        \n    Returns:\n        Tuple of feature dictionaries, one per token\n    \"\"\"\n    return tuple(features_from_word(sentence, index) for index in range(len(sentence)))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def _voidtoken():\n    \"\"\"\n    Create a placeholder token with empty features.\n    \n    Used when expert.ai tokenization doesn't align with the original\n    tokenization and no matching token can be found.\n    \n    Returns:\n        Dictionary with empty/default values for all token features\n    \"\"\"\n    return {\n        'word': '',\n        'pos': '',\n        'syncon': -1,\n        'ancestor': -1,\n        'dep': '',\n        'label': ''\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Process Data Through expert.ai and Extract Features\n\nThis step analyzes all sentences through the expert.ai NLP engine and extracts the linguistic features. Processing ~20,000 sentences takes approximately 1 hour.\n\n> **NOTE**: This cell requires the Edge NL API runtime to be running locally."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze all sentences through expert.ai NLP engine\n# This is the most time-consuming step (~1 hour for the full dataset)\ntrain_docs = tokens_to_docs(raw_train, client)\ntest_docs = tokens_to_docs(raw_test, client)\nvalid_docs = tokens_to_docs(raw_valid, client)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract structured features from the analyzed documents\n# Aligns original tokens with expert.ai tokens and creates feature dictionaries\ntrain = features_from_docs(raw_train, train_docs)\ntest = features_from_docs(raw_test, test_docs)\nvalid = features_from_docs(raw_valid, valid_docs)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect example features for a sample sentence\n# Shows how expert.ai enriches tokens with semantic information\nimport pprint\np_idx = 2\n\nprint(\"Original sentence:\", raw_train[p_idx])\nprint(\"NER labels:\", y_train[p_idx])\nprint('')\nprint(\"Extracted features per token:\")\npprint.pprint(train[p_idx])\nprint('')\nprint(\"Raw expert.ai token objects:\")\npprint.pprint([tk.__dict__ for tk in train_docs[p_idx].tokens])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Build Final Feature Vectors for CRF\n\nConvert the extracted features into the format expected by sklearn-crfsuite, adding context window features (previous and next token features)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build final feature vectors with context windows for each dataset split\nX_train = [features_from_sentence(sentence) for sentence in train]\nX_test = [features_from_sentence(sentence) for sentence in test]\nX_valid = [features_from_sentence(sentence) for sentence in valid]\n\n# Display example feature vector for one sentence\nprint(\"Example feature vectors for sentence:\")\npprint.pprint(X_train[1])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training the CRF Model\n\nTrain a Conditional Random Field model using the L-BFGS optimization algorithm. The CRF learns to predict NER labels by modeling the conditional probability of label sequences given the input features.\n\n**Hyperparameters:**\n- `c1=0.1`: L1 regularization coefficient (promotes sparse features)\n- `c2=0.5`: L2 regularization coefficient (prevents overfitting)\n- `max_iterations=800`: Maximum optimization iterations\n- `all_possible_transitions=True`: Include transitions not observed in training data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Train the CRF model\ncrf = sklearn_crfsuite.CRF(\n    algorithm='lbfgs',      # Limited-memory BFGS optimization\n    c1=0.1,                 # L1 regularization\n    c2=0.5,                 # L2 regularization\n    max_iterations=800,     # Max training iterations\n    all_possible_transitions=True,  # Allow unseen label transitions\n    verbose=True\n)\n\n# Fit with development set for monitoring convergence\ncrf.fit(X_train, y_train, X_dev=X_valid, y_dev=y_valid)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Model Evaluation\n\nEvaluate the trained model on both the test and validation sets using standard NER metrics:\n- **Precision**: Proportion of predicted entities that are correct\n- **Recall**: Proportion of actual entities that were found\n- **F1-score**: Harmonic mean of precision and recall"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n\ndef compute_prediction_latency(dataset, model, n_instances=-1):\n    \"\"\"\n    Measure the average prediction latency per instance.\n    \n    Args:\n        dataset: Input data to predict on\n        model: Trained model with a predict() method\n        n_instances: Number of instances to average over (-1 = all)\n        \n    Returns:\n        Average prediction time in seconds per instance\n    \"\"\"\n    if n_instances == -1:\n        n_instances = len(dataset)\n    start_time = time.process_time()\n    model.predict(dataset)\n    total_latency = time.process_time() - start_time\n    return total_latency / n_instances"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model size (number of learned feature weights)\nprint('Model size: {:0.2f}M parameters'.format(crf.size_ / 1000000))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Inference speed (average time to predict one sentence)\nprint(f'Prediction latency: {compute_prediction_latency(X_test, crf):.3} seconds per sentence')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate on test and validation sets using seqeval\n# (entity-level evaluation that accounts for BIO boundaries)\nfrom seqeval.metrics import classification_report\n\ndatasets = [('Test Set', X_test, y_test), ('Validation Set', X_valid, y_valid)]\n\nfor title, X, Y in datasets:\n    Y_pred = crf.predict(X)\n    print(f\"=== {title} ===\")\n    print(classification_report(Y, Y_pred, digits=3))\n    print('\\n')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}